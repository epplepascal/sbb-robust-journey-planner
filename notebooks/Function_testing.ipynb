{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "046c89ed-ecea-4c9e-bdb5-13aee21cf58e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gmaps\n",
      "  Downloading gmaps-0.9.0.tar.gz (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting googlemaps\n",
      "  Downloading googlemaps-4.10.0.tar.gz (33 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: ipython>=5.3.0 in /opt/conda/lib/python3.9/site-packages (from gmaps) (8.3.0)\n",
      "Requirement already satisfied: ipywidgets>=7.0.0 in /opt/conda/lib/python3.9/site-packages (from gmaps) (8.0.4)\n",
      "Requirement already satisfied: traitlets>=4.3.0 in /opt/conda/lib/python3.9/site-packages (from gmaps) (5.7.1)\n",
      "Collecting geojson>=2.0.0\n",
      "  Downloading geojson-3.0.1-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.9/site-packages (from gmaps) (1.16.0)\n",
      "Requirement already satisfied: requests<3.0,>=2.20.0 in /opt/conda/lib/python3.9/site-packages (from googlemaps) (2.27.1)\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.9/site-packages (from ipython>=5.3.0->gmaps) (62.2.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.9/site-packages (from ipython>=5.3.0->gmaps) (5.1.1)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.9/site-packages (from ipython>=5.3.0->gmaps) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from ipython>=5.3.0->gmaps) (3.0.38)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.9/site-packages (from ipython>=5.3.0->gmaps) (0.2.0)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.9/site-packages (from ipython>=5.3.0->gmaps) (2.12.0)\n",
      "Requirement already satisfied: stack-data in /opt/conda/lib/python3.9/site-packages (from ipython>=5.3.0->gmaps) (0.2.0)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.9/site-packages (from ipython>=5.3.0->gmaps) (0.1.3)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.9/site-packages (from ipython>=5.3.0->gmaps) (4.8.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.9/site-packages (from ipython>=5.3.0->gmaps) (0.18.1)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0 in /opt/conda/lib/python3.9/site-packages (from ipywidgets>=7.0.0->gmaps) (4.0.5)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /opt/conda/lib/python3.9/site-packages (from ipywidgets>=7.0.0->gmaps) (6.22.0)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0 in /opt/conda/lib/python3.9/site-packages (from ipywidgets>=7.0.0->gmaps) (3.0.5)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests<3.0,>=2.20.0->googlemaps) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests<3.0,>=2.20.0->googlemaps) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests<3.0,>=2.20.0->googlemaps) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests<3.0,>=2.20.0->googlemaps) (2022.9.24)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /opt/conda/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->gmaps) (5.3.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->gmaps) (21.3)\n",
      "Requirement already satisfied: tornado>=6.1 in /opt/conda/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->gmaps) (6.1)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /opt/conda/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->gmaps) (1.6.7)\n",
      "Requirement already satisfied: comm>=0.1.1 in /opt/conda/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->gmaps) (0.1.3)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->gmaps) (5.9.0)\n",
      "Requirement already satisfied: nest-asyncio in /opt/conda/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->gmaps) (1.5.5)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /opt/conda/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->gmaps) (7.3.1)\n",
      "Requirement already satisfied: pyzmq>=20 in /opt/conda/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->gmaps) (22.3.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.9/site-packages (from jedi>=0.16->ipython>=5.3.0->gmaps) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.9/site-packages (from pexpect>4.3->ipython>=5.3.0->gmaps) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.9/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.3.0->gmaps) (0.2.5)\n",
      "Requirement already satisfied: pure-eval in /opt/conda/lib/python3.9/site-packages (from stack-data->ipython>=5.3.0->gmaps) (0.2.2)\n",
      "Requirement already satisfied: asttokens in /opt/conda/lib/python3.9/site-packages (from stack-data->ipython>=5.3.0->gmaps) (2.0.5)\n",
      "Requirement already satisfied: executing in /opt/conda/lib/python3.9/site-packages (from stack-data->ipython>=5.3.0->gmaps) (0.8.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.9/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets>=7.0.0->gmaps) (2.8.2)\n",
      "Requirement already satisfied: entrypoints in /opt/conda/lib/python3.9/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets>=7.0.0->gmaps) (0.4)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /opt/conda/lib/python3.9/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel>=4.5.1->ipywidgets>=7.0.0->gmaps) (2.5.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging->ipykernel>=4.5.1->ipywidgets>=7.0.0->gmaps) (3.0.9)\n",
      "Building wheels for collected packages: gmaps, googlemaps\n",
      "  Building wheel for gmaps (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gmaps: filename=gmaps-0.9.0-py2.py3-none-any.whl size=2076090 sha256=a8d125cd34cc4c3297991bc8ce1fec4d11b80171ddec17a9287289921c5faefe\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/66/ab/29/3032938612273665f0fa4d2fab4e3ecfe86480eaaa40aaee91\n",
      "  Building wheel for googlemaps (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for googlemaps: filename=googlemaps-4.10.0-py3-none-any.whl size=40717 sha256=a8dd76fa51f49dd712a30a25579da50bc42d52801121200ebdb5c5f5a554855d\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/d9/5f/46/54a2bdb4bcb07d3faba4463d2884865705914cc72a7b8bb5f0\n",
      "Successfully built gmaps googlemaps\n",
      "Installing collected packages: geojson, googlemaps, gmaps\n",
      "Successfully installed geojson-3.0.1 gmaps-0.9.0 googlemaps-4.10.0\n"
     ]
    }
   ],
   "source": [
    "!pip install gmaps googlemaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3aaebb78-f234-4865-bfb3-e73bc8ea0697",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import gmaps\n",
    "from datetime import datetime\n",
    "import googlemaps\n",
    "import numpy as np\n",
    "import random\n",
    "import datetime\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0765c27f-f3e3-4068-87ac-ac51925db1ff",
   "metadata": {},
   "source": [
    "## Evaluation of the Algorithm\n",
    "\n",
    "In order to provide an objective evaluation of the algorithm we implemented, we decided to compare it with Google Maps. So, we selected 900 random combinations of the stops in Zürich and input these on Google Maps and on our algorithm. \n",
    "Thhe comparison is made taking the difference between the performance of Google Maps and our algorithm based on the following parameters:\n",
    "- total trip duration\n",
    "- number of changes \n",
    "- walking time\n",
    "\n",
    "First we installed Google Maps' API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb6f1fc4-7725-4752-a2c2-4c151a88d422",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmaps = googlemaps.Client(key='AIzaSyAgSWKN9Ky4vZFgoqpwsjbVgKwGmjX6nWk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc2256b8-44c7-4474-a426-6a489cd5b187",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'APIkey.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAPIkey.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      2\u001b[0m     api_key \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mreadline()\n\u001b[1;32m      3\u001b[0m     f\u001b[38;5;241m.\u001b[39mclose\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'APIkey.txt'"
     ]
    }
   ],
   "source": [
    "with open('APIkey.txt') as f:\n",
    "    api_key = f.readline()\n",
    "    f.close\n",
    "\n",
    "# Create an instance of the Google Maps client\n",
    "gmaps = googlemaps.Client(key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f068c28-5e7c-4388-b16a-5c6251049593",
   "metadata": {},
   "source": [
    "Load the data of the stops that we wont the test to be carried on, these are taken randomly from the total combinations of stops that you can find in Zürich. The code for where the file 'stops_with_lonlat.csv' is taken can be found in the distances_calculation.ipynb notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "319ca34a-06f3-4d33-82d1-30ac8f34cf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = pd.read_csv('stops_with_lonlat.csv')\n",
    "stops = stops[['stop_id1', 'stop_id2', 'latitude1', 'longitude1', 'latitude2', 'longitude2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31813be6-d7e9-4a43-b0e0-85c0f40359f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_time_CSA = random.sample(list(np.arange(21600,72000, dtype=float)), 900)\n",
    "\n",
    "# Convert departure times to datetime objects\n",
    "arr_time_GM = []\n",
    "for seconds in arr_time_CSA:\n",
    "    dt = datetime.datetime.utcfromtimestamp(seconds)\n",
    "    arr_time_GM.append(dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd8d6ee-0714-4f45-9b13-2e564888fca4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Function for comparing Google Maps and CSA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612dd0c5-ba3b-4bd6-92ba-5914f790791b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import the CSA algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96162d51-e367-41e7-a05b-a0a01bfc4ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from array import array\n",
    "\n",
    "def reset_timetable(timetable, original_length):\n",
    "    for id, conn in enumerate(timetable):\n",
    "        timetable[id] = conn._replace(active = 1)\n",
    "    return timetable[:original_length]\n",
    "### WORKING CSA\n",
    "def CSA(stations, timetable, departure_station, departure_time, arrival_station, arrival_time):\n",
    "    MAX_INT = 2**32 - 1\n",
    "\n",
    "    earliest = MAX_INT\n",
    "    \n",
    "    in_connection = {s: MAX_INT for s in stations}\n",
    "    earliest_arrival = {s: MAX_INT for s in stations}\n",
    "    \n",
    "    earliest_arrival[departure_station] = departure_time\n",
    "    \n",
    "    if transfer_dict.get(departure_station) is not None:\n",
    "        for reachable_station, transfer_time in transfer_dict[departure_station]:\n",
    "            arrival_time_reachable = departure_time + transfer_time\n",
    "            earliest_arrival[reachable_station] = arrival_time_reachable\n",
    "            walking_connection = Connection('W', departure_station, reachable_station, departure_time, arrival_time_reachable, 'W', 1)\n",
    "            timetable.append(walking_connection)\n",
    "            in_connection[reachable_station] = len(timetable) - 1 #get last index of timetable\n",
    "    \n",
    "    for i, c in enumerate(timetable):\n",
    "        \n",
    "        change = 0\n",
    "        \n",
    "        if c.active == 1:\n",
    "            \n",
    "            if (in_connection.get(c.dep_stop) is not None): #sanity\n",
    "                if (in_connection[c.dep_stop] != MAX_INT):\n",
    "                    #print(i, in_connection[c.dep_stop])\n",
    "                    if (timetable[in_connection[c.dep_stop]].trip_id != c.trip_id):\n",
    "                            change = 120 #transfer time penalty in seconds\n",
    "\n",
    "            if (c.dep_time_sec >= earliest_arrival[c.dep_stop] + change) & (c.arr_time_sec < earliest_arrival[c.arr_stop]):\n",
    "                \n",
    "                \n",
    "                earliest_arrival[c.arr_stop] = c.arr_time_sec\n",
    "                in_connection[c.arr_stop] = i\n",
    "\n",
    "                if c.arr_stop == arrival_station:\n",
    "                    earliest = min(earliest, c.arr_time_sec)\n",
    "\n",
    "                ## transfers\n",
    "                if transfer_dict.get(c.arr_stop) is not None: ### inconsistency between the tables\n",
    "                        for reachable_station, transfer_time in transfer_dict[c.arr_stop]:\n",
    "                            arrival_time_reachable = c.arr_time_sec + transfer_time\n",
    "                            if reachable_station in stations: ### inconsistency \n",
    "                                if (arrival_time_reachable < earliest_arrival[reachable_station]):\n",
    "                                    \n",
    "                                    earliest_arrival[reachable_station] = arrival_time_reachable\n",
    "                                    # Append the 'walking' as a new connection to the timetable\n",
    "                                    walking_connection = Connection('W', c.arr_stop, reachable_station, c.arr_time_sec, arrival_time_reachable, 'W', 1)\n",
    "                                    #print(walking_connection)\n",
    "                                    timetable.append(walking_connection)\n",
    "                                    in_connection[reachable_station] = len(timetable) - 1 #get last index of timetable\n",
    "\n",
    "                                    if reachable_station == arrival_station:\n",
    "                                        earliest = min(earliest, arrival_time_reachable)\n",
    "\n",
    "            elif c.arr_time_sec > earliest:\n",
    "                break\n",
    "\n",
    "    route = []\n",
    "    # We have to rebuild the route from the arrival station\n",
    "    last_connection_index = in_connection[arrival_station]\n",
    "\n",
    "    while last_connection_index != MAX_INT:\n",
    "        connection = timetable[last_connection_index]\n",
    "        route.append(connection)\n",
    "        last_connection_index = in_connection[connection.dep_stop]\n",
    "    \n",
    "    route=list(reversed(route))\n",
    "    \n",
    "    return route"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38db1027-f52b-4096-8273-2de8c55c5330",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Retrieve the data in order to be able to run CSA\n",
    "\n",
    "Stop transfers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76080273-b23f-4d7d-bf1a-aa318b95a9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_times = pd.read_csv('df_with_transfer_time.csv')\n",
    "transfer_times['stop_id1'] = transfer_times['stop_id1'].astype('string')\n",
    "transfer_times['stop_id2'] = transfer_times['stop_id2'].astype('string')\n",
    "\n",
    "transfer_dict = {}\n",
    "for _, row in transfer_times.iterrows():\n",
    "    if row.stop_id1 not in transfer_dict:\n",
    "        transfer_dict[row.stop_id1] = [(row.stop_id2, row.walking_time)]\n",
    "    elif (row.stop_id2, row.walking_time) not in transfer_dict[row.stop_id1]:\n",
    "        transfer_dict[row.stop_id1].append((row.stop_id2, row.walking_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8392060b-6a29-4633-b016-2609724daea7",
   "metadata": {},
   "source": [
    "Timetable data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05c6fc0-88cd-4abe-ab80-1cbcfd41b766",
   "metadata": {},
   "outputs": [],
   "source": [
    "timetable = pd.read_pickle('timetable_zh_latest_2.pkl')\n",
    "timetable.columns = ['stop_id', 'trip_id', 'stop_name', 'dep_stop', 'arr_stop',\n",
    "       'dep_time', 'arr_time', 'route_desc', 'monday',\n",
    "       'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday']\n",
    "timetable[\"active\"] = 1\n",
    "\n",
    "def get_sec(time_str):\n",
    "    h, m, s = time_str.split(':')\n",
    "    return int(h) * 3600 + int(m) * 60 + int(s)\n",
    "\n",
    "timetable['dep_time_sec'] = timetable['dep_time'].apply(get_sec)\n",
    "timetable['arr_time_sec'] = timetable['arr_time'].apply(get_sec)\n",
    "timetable.drop('dep_time', axis=1, inplace=True)\n",
    "timetable.drop('arr_time', axis=1, inplace=True)\n",
    "\n",
    "columns_to_compare = ['dep_stop', 'arr_stop', 'monday', 'tuesday', 'wednesday','thursday', 'friday', 'saturday', 'sunday', 'dep_time_sec','arr_time_sec']\n",
    "duplicates = timetable.duplicated(subset=columns_to_compare, keep=False) \n",
    "timetable = timetable[~duplicates]\n",
    "wrong_entries = timetable['arr_time_sec'] <= timetable['dep_time_sec'] ## added\n",
    "timetable = timetable[~wrong_entries]\n",
    "timetable['trip_id'] = timetable['trip_id'].astype('string')\n",
    "timetable['dep_stop'] = timetable['dep_stop'].astype('string')\n",
    "timetable['arr_stop'] = timetable['arr_stop'].astype('string')\n",
    "\n",
    "Connection = namedtuple('connection', ['trip_id', 'dep_stop', 'arr_stop', 'dep_time_sec', 'arr_time_sec', 'route_desc', 'active'])\n",
    "cols = ['trip_id', 'dep_stop', 'arr_stop', 'dep_time_sec', 'arr_time_sec', 'route_desc']\n",
    "timetable_monday = timetable[timetable['monday'] == 1][cols].sort_values(by = 'dep_time_sec').reset_index(drop = True)\n",
    "\n",
    "ls_timetable = []\n",
    "for _, connection in timetable_monday.iterrows():\n",
    "    ls_timetable.append(Connection(connection.trip_id, connection.dep_stop, connection.arr_stop, connection.dep_time_sec, connection.arr_time_sec, connection.route_desc, 1))\n",
    "original_length = len(ls_timetable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a159cab-d1a9-4769-ac34-2b6b6e3af45d",
   "metadata": {},
   "source": [
    "Stations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a26668d-2e39-4cf4-ab73-86aae375eafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zurich = pd.read_csv('df_zurich.csv')\n",
    "stations = set(df_zurich['stop_id'].to_list() + timetable['dep_stop'].to_list() + timetable['arr_stop'].to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766f86bd-9e54-4aec-a084-a5d3971d22d6",
   "metadata": {},
   "source": [
    "## Run the evaluation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80875b63-7202-4f44-b54d-d216c8073f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_csa_compared_googlemaps(stations, testing_df, ls_timetable, print_ = False):\n",
    "    diff_duration_list = []\n",
    "    diff_walking_list = []\n",
    "    diff_nchanges_list = []\n",
    "    \n",
    "    needs_more_time = 0\n",
    "    won = 0\n",
    "\n",
    "    for i in range(0,900):        \n",
    "        # get the longitude and latitude of the stops\n",
    "        stop1, lon1, lat1 = row = testing_df.loc[i, ['stop_id1', 'latitude1', 'longitude1']]\n",
    "        stop2, lon2, lat2 = row = testing_df.loc[i, ['stop_id2', 'latitude2', 'longitude2']]  \n",
    "\n",
    "        current_datetime = datetime.now()\n",
    "        yesterday_datetime = current_datetime - timedelta(days=1)\n",
    "        desired_datetime = yesterday_datetime.replace(hour=15, minute=0, second=0, microsecond=0)\n",
    "\n",
    "        departure_time_GM = desired_datetime\n",
    "        departure_time_CSA = departure_time_CSA.time().hour * 3600 + dt.time().minute * 60 + departure_time_CSA.time().second\n",
    "\n",
    "        \n",
    "        # Google Maps directions\n",
    "        directions_result = gmaps.directions(f\"{lon1}, {lat1}\", f\"{lon2}, {lat2}\",\n",
    "                                            mode=\"driving\",\n",
    "                                            arrival_time = arr_time_GM[i])\n",
    "        \n",
    "        # CSA directions\n",
    "        directions_result_csa = CSA(stations, ls_timetable, stop1, departure_time_CSA, stop2, arrival_time)\n",
    "        \n",
    "        if len(directions_result_csa) == 0:\n",
    "            if print_ == True:\n",
    "                print(f'The connection {i} from stop {stop1} to {stop2} at time {departure_time} to {arrival_time} does not exist, sorry!')\n",
    "            needs_more_time += 1\n",
    "            continue\n",
    "\n",
    "        ##### TIME OF THE TRIP #####\n",
    "        duration_gm = directions_result[0]['legs'][0]['duration']['text'].split(' ')\n",
    "        total_duration_gm = float(duration_gm[0]) * 60     #Google Maps\n",
    "        if len(duration_gm) > 2:\n",
    "             total_duration_gm += int(duration_gm[2])\n",
    "        total_duration_csa = - directions_result_csa[0].dep_time_sec + directions_result_csa[-1].arr_time_sec   # CSA\n",
    "        \n",
    "        if total_duration_csa > 10800:\n",
    "            if print_ == True:\n",
    "                print(f'The connection {i} from stop {stop1} to {stop2} at time {departure_time} to {arrival_time} needs a greater time frame.')\n",
    "            needs_more_time += 1\n",
    "            continue\n",
    "            \n",
    "        # FUNCTION FOR Google Maps\n",
    "        walking_distance_gm, n_changes_gm = 0, 0\n",
    "        for step in directions_result[0]['legs'][0]['steps']:\n",
    "            if 'transit_details' in step:\n",
    "                n_changes_gm += 1\n",
    "            else:\n",
    "                walking_distance_gm += step['distance']['value']\n",
    "                \n",
    "        # FUNCTION FOR CSA\n",
    "        walking_distance_csa, n_changes_csa = 0.0, 0\n",
    "        for j in range(len(directions_result_csa)):\n",
    "            if directions_result_csa[j].trip_id == 'W':\n",
    "                walking_distance_csa += (directions_result_csa[j].arr_time_sec - directions_result_csa[j].dep_time_sec) / 60 * 50\n",
    "            n_changes_csa += 1\n",
    "\n",
    "        # compute the differences and append them to the list\n",
    "        diff_duration = total_duration_gm - total_duration_csa\n",
    "        diff_walking = walking_distance_gm - walking_distance_csa\n",
    "        diff_nchanges = n_changes_gm - 1 - n_changes_csa\n",
    "        \n",
    "        diff_duration_list.append(diff_duration)\n",
    "        diff_walking_list.append(diff_walking)\n",
    "        diff_nchanges_list.append(diff_nchanges)\n",
    "    \n",
    "    print(f'On average we found {100 - (needs_more_time / 900 * 100)} % connections in the time frame of 3h.')\n",
    "    \n",
    "    return diff_duration_list, diff_walking_list, diff_nchanges_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06574546-5b5b-4f39-ab23-880843e7814a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On average we found 96.22222222222223 % connections in the time frame of 3h.\n"
     ]
    }
   ],
   "source": [
    "diff_duration_list, diff_walking_list, diff_nchanges_list = performance_csa_compared_googlemaps(stations,\n",
    "                                                                                                stops,\n",
    "                                                                                                arr_time_CSA, \n",
    "                                                                                                arr_time_GM, \n",
    "                                                                                                ls_timetable,\n",
    "                                                                                                print_ = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be6c750-2256-453a-bbb3-4c317d42cc46",
   "metadata": {},
   "source": [
    "### Plot of the differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b5772af-f38b-45a0-a2f3-6eaedccbc60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert from seconds to minutes for better readability in the plots:\n",
    "\n",
    "def seconds_to_minutes(seconds_list):\n",
    "    minutes_list = []\n",
    "    for seconds in seconds_list:\n",
    "        minutes = float(seconds) / 60.0\n",
    "        minutes_list.append(minutes)\n",
    "    return minutes_list\n",
    "\n",
    "diff_duration_list = seconds_to_minutes(diff_duration_list)\n",
    "diff_walking_list = seconds_to_minutes(diff_walking_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac77d54-0b16-431a-b1b0-4d51bac8563f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Create subplots with histograms\n",
    "fig, axs = plt.subplots(1, 3, figsize=(20, 10))\n",
    "\n",
    "# Plot histogram for duration\n",
    "axs[0].hist(diff_duration_list, bins=30, edgecolor='black')\n",
    "axs[0].set_title('Duration difference between Google Maps and CSA trips')\n",
    "\n",
    "# Calculate median for duration\n",
    "mean_duration = np.mean(diff_duration_list)\n",
    "axs[0].axvline(mean_duration, color='red', linestyle='dashed', linewidth=2)\n",
    "axs[0].legend(['Mean: {:.2f}'.format(mean_duration)], loc='upper right')\n",
    "\n",
    "# Plot histogram for number of changes\n",
    "axs[1].hist(diff_nchanges_list, bins=30, edgecolor='black')\n",
    "axs[1].set_title('Number of changes difference between Google Maps and CSA trips')\n",
    "\n",
    "# Calculate median for number of changes\n",
    "mean_nchanges = np.mean(diff_nchanges_list)\n",
    "axs[1].axvline(mean_nchanges, color='red', linestyle='dashed', linewidth=2)\n",
    "axs[1].legend(['Mean: {:.2f}'.format(mean_nchanges)], loc='upper right')\n",
    "\n",
    "# Plot histogram for walking time\n",
    "axs[2].hist(diff_walking_list, bins=30, edgecolor='black')\n",
    "axs[2].set_title('Walking difference between Google Maps and CSA trips')\n",
    "\n",
    "# Calculate median for walking time\n",
    "mean_walking = np.mean(diff_walking_list)\n",
    "axs[2].axvline(mean_walking, color='red', linestyle='dashed', linewidth=2)\n",
    "axs[2].legend(['Mean: {:.2f}'.format(mean_walking)], loc='upper right')\n",
    "\n",
    "# Adjust spacing between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the subplots\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd19977-a547-4f69-9768-bb38bbd92763",
   "metadata": {},
   "source": [
    "# Final Evaluation:\n",
    "\n",
    "In these plots the distribution of the difference between Google Maps and our algorithm is displayed:\n",
    "\n",
    "1. **Total distance**: The first plot shows the difference in total trip's duration between Google Maps and our algorithm. The negative values mean that Google Maps' trip is faster that the one we propose with our algorithm and viceversa. It shows that Google Maps it’s on average faster of 0.37 minutes than our algorithms, which is a negligible difference. The maximum delay computed is 2 minutes with respect to Google maps, while there are a -...- percentage of times when the algorithm proposes a shorter path than Google Maps. \n",
    "2. **Number of changes**: The central plot shows the difference in number of changes of means of transport between Google Maps and our algorithm. Negative values mean that Google maps propose a trip which requires more changes. It shows that Google Maps it’s on average proposing less trips than our algorithm, specifically ... less changes than our algorithm. This may be due to the fact that Google Maps imposes a limit on the number of changes per hour inn order to be more user friendly while we did not introduce and threshold. \n",
    "3. **Walking time**: The right plot shows the difference in total time spent walking over the trip between Google Maps and our algorithm. Negative values mean that Google Maps proposes a trip which requires less time walking than ours and viceversa. It shows that Google Maps it’s on average proposing trips that require walking more than our algorithm, specifically ... minute more than our algorithm. This may be due to the fact that we computed the distance between the stops on-flight, and not taking into consideration buildings, elevation and other impeding factors. Therefore, the walking time ends up being less.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "Lastly, let’s consider the advantages and limitations of our solution. One limitation it’s that on average we compute 11 changes and this is a considerable amount which may be non optimal for the user. This is due to the fact we did not implement a limit on the number of changes. Another limitation is that the walking time is computed on one flight distance, therefore disregarding building, elevation and other factors. Instead, the main advantage of our solution is the fact that it’s adding the success probability of the trips which respect to google maps, but still performing comparably."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
