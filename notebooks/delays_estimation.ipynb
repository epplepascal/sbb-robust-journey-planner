{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf023d9a-be07-45d4-a120-d573443f3c7c",
   "metadata": {},
   "source": [
    "# Delays estimation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a15c43-7a0f-4e70-b117-f11ec94fe852",
   "metadata": {},
   "source": [
    "In this notebook we work with the table sbb_orc_istdaten_new which is the dataset istdaten with only the stops in a radius of 18km around Zurich HB. We estimate the probability of all the possibles combinations we asummed (type of transport, daytime and day of the week). Then we store all these probabilities in a dataframe which will be reuse to compute the confidence of a trip. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46274b11-ef92-41fc-81ec-9a4bcf76df00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e224d52-7c5f-426a-9f52-cf58875c562e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyhive import hive\n",
    "\n",
    "# Set python variables from environment variables\n",
    "username = os.environ['USERNAME']\n",
    "hive_host = os.environ['HIVE_SERVER2'].split(':')[0]\n",
    "hive_port = os.environ['HIVE_SERVER2'].split(':')[1]\n",
    "\n",
    "# create connection\n",
    "conn = hive.connect(\n",
    "    host=hive_host,\n",
    "    port=hive_port)\n",
    "\n",
    "# create cursor\n",
    "cur = conn.cursor()\n",
    "\n",
    "print(f\"your username is {username}\")\n",
    "print(f\"you are connected to {hive_host}:{hive_port}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641a5012-28fb-4062-a07c-beb348afb674",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f'CREATE DATABASE IF NOT EXISTS {username}'\n",
    "cur.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8016d652-1ff4-491f-9ff6-7b036a12dfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"USE {username}\"\n",
    "cur.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cab9271-44a5-478c-bb12-641e02471160",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sparkmagic.magics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8571ba-4a13-4d9e-90ec-3fdbca33431e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import get_ipython\n",
    "username = os.environ['RENKU_USERNAME']\n",
    "server = \"http://iccluster044.iccluster.epfl.ch:8998\"\n",
    "\n",
    "# set the application name as \"<your_gaspar_id>-homework3\"\n",
    "get_ipython().run_cell_magic(\n",
    "    'spark',\n",
    "    line='config', \n",
    "    cell=\"\"\"{{ \"name\": \"{0}-final-project2\", \"executorMemory\": \"4G\", \"executorCores\": 4, \"numExecutors\": 10, \"driverMemory\": \"4G\" }}\"\"\".format(username)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2f0c86-2dfe-432a-8608-f6e3e0b8e5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ipython().run_line_magic(\n",
    "    \"spark\", f\"\"\"add -s {username}-final-project2 -l python -u {server} -k\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c866fbd4-d4e9-469f-af30-93d62ef9e78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "#load a istdaten with the only the stops around 18km around Zurich\n",
    "df_valid = spark.read.orc(f\"/user/epple/hive/sbb_orc_istdaten_new\")\n",
    "df_valid.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195edac0-5cb1-48c0-af38-8147064506aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "df = df_valid.sample(0.01)  #we work on a sample of 1% of istdaten randomly chosen\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f66b2c5-bfec-42a7-8a9a-f12ad2f567e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import DataFrameStatFunctions\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import col, lower, to_timestamp, date_format, avg, hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff181bf-6dd9-443c-bc41-a360fa7429d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "#compute the delays actual_arrival - expected_arrival\n",
    "df_delays = df.select('*', (F.unix_timestamp(F.to_timestamp(df.an_prognose, format ='dd.MM.yyyy HH:mm:ss')) - F.unix_timestamp(F.to_timestamp(df.ankunftszeit,format ='dd.MM.yyyy HH:mm'))).alias('delay'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903ac261-ac8a-45c8-a63a-004b28e23f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "#select only the useful columns stop_id, type of transport, stop name, expected_arrival, actual_arrival, delay \n",
    "ls = ['fahrt_bezeichner','produkt_id', 'haltestellen_name', 'ankunftszeit', 'an_prognose', 'delay']\n",
    "df_delays_filter = df_delays.select(ls)\n",
    "df_delays_filter.show(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0222c1bb-3ceb-423d-9581-654a41257b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "#change the negative delays to 0\n",
    "df_delays_filter = df_delays_filter.withColumn(\"positive_delay\", F.when(df_delays.delay > 0, df_delays.delay).otherwise(0))\n",
    "df_delays_filter.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16da4586-6afd-4e7f-b6ac-b88a4159ab78",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "#change the type of transport to lowercase because there are 2 types bus (BUS, bus)\n",
    "df_delays_filter = df_delays_filter.withColumn('produkt_id', lower(col('produkt_id')));\n",
    "df_delays_filter.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2a61b6-8db8-48b9-a334-ca088885b937",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "#remove the rows without data on delays\n",
    "df_delays_filter = df_delays_filter.filter(col(\"delay\").isNotNull())\n",
    "df_delays_filter.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe78519-25ad-42db-9c1c-6ca903195b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "#add a column with the day of the week\n",
    "df_days_w = df_delays_filter.withColumn(\"an_prognose\",F.to_timestamp(col(\"an_prognose\"), format ='dd.MM.yyyy HH:mm:ss')).withColumn(\"week_day_abb\", date_format(col(\"an_prognose\"), \"E\"))\n",
    "df_days_w.show(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06da216-490f-4236-aeb9-d64a064073df",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "#create a list with all the days of the week\n",
    "days =df_days_w.select('week_day_abb').distinct().rdd.flatMap(lambda x: x).collect()\n",
    "print(days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dc72e4-5069-4ec7-9456-61064dde7c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "#create a list with all the type of transport\n",
    "#we do not consider the funicular\n",
    "ttype = df_delays_filter.select('produkt_id').distinct().rdd.flatMap(lambda x: x).collect()\n",
    "ttype = ttype[:3]\n",
    "print(ttype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f187a4-5a7e-4381-890f-083e69a07f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "#extract the hours of the trip\n",
    "df_days_w =df_days_w.withColumn(\"hours\", hour(col(\"an_prognose\")))\n",
    "df_days_w.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6757ff11-37b3-4b0b-a188-30f239c59c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "# create a list called combinations with all the possible combinations \n",
    "# create a list called bacth with all delays threshold between 0 to 200s in range of 20s\n",
    "batch = list(range(0,220,20))\n",
    "comb = []\n",
    "for i in range(len(batch)-1):\n",
    "    tmp = str(batch[i]) + \"-\" + str(batch[i+1])\n",
    "    comb.append(tmp)  # create a list with 2 batch together \n",
    "    \n",
    "days = ['Mon', 'Tue', 'Wed', 'Thu','Fri', 'Sat', 'Sun']\n",
    "ttype = ['bus', 'tram', 'zug']\n",
    "hours_merge = ['6h-9h', '9h-16h','16-21h']\n",
    "hours = [6,9,16,21]\n",
    "\n",
    "\n",
    "combinations = []  #will be a list with all the possible combinations between the days, type of transport and moment in the day \n",
    "for week in days:\n",
    "    for type in ttype:\n",
    "        for h in hours_merge:\n",
    "            # Create a combination by concatenating the week name and type\n",
    "            combination = week + \" - \" + type + \" \" + h\n",
    "            # Add the combination to the list\n",
    "            combinations.append(combination)  \n",
    "\n",
    "\n",
    "columns = comb\n",
    "rows = combinations\n",
    "\n",
    "# create an empty df to store all the info we will collect for the statistics\n",
    "df_stat_ist = pd.DataFrame(columns=columns, index=rows)   #create an empty dataframe with all the combinations as rows and the batch as columns\n",
    "df_stat_ist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2df15b-b679-451a-b2ff-c23eac1968a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "#fill out the dataframe\n",
    "k = 0\n",
    "for idx,day in enumerate(days):\n",
    "    for idx2,t in enumerate(ttype):\n",
    "        w = 0\n",
    "        for h in range(len(hours)-1):\n",
    "            for i in range(len(batch)-1):\n",
    "                number = df_days_w.filter((df_days_w.positive_delay >= batch[i] ) & (df_days_w.positive_delay < batch[i+1]) & (df_days_w.week_day_abb == day) & (df_days_w.produkt_id == t ) & (df_days_w.hours >= hours[h] ) & (df_days_w.hours < hours[h+1]) ).count()\n",
    "                df_stat_ist.iloc[k+w,i] = number\n",
    "            w = w + 1\n",
    "        k = k + 3\n",
    "df_stat_ist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88b3ccd-acff-4b0e-ba8d-13ccf1f32fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark -o df_istaden_stat -n -1\n",
    "df_istaden_stat = spark.createDataFrame(df_stat_ist.reset_index())  # transfer into a spark df and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854c7af1-57dd-40e8-9907-c9952b478266",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_istaden_stat.to_csv(\"stat_timeday.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0d2f1d-81b9-4a98-ac0e-f155851dfa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the df with all the statistics\n",
    "stat_istdaten = pd.read_csv('stat_timeday.csv')\n",
    "indexx = stat_istdaten['index']\n",
    "stat_istdaten.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de16e3ed-59e7-4582-b25b-007c6e8a5728",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove useless columns\n",
    "stat_istdaten.drop(['Unnamed: 0', 'index'],axis=1, inplace=True)\n",
    "stat_istdaten.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a195660b-84c4-4cd8-943d-12cc57894c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if the statistics we computed on istdaten make sense by plotting the distribution on 1 line\n",
    "frequencies = stat_istdaten.iloc[60].tolist()[0:]\n",
    "bin_ranges = list(range(0,220,20))\n",
    "bin_centers = [(bin_ranges[i] + bin_ranges[i+1]) / 2 for i in range(len(bin_ranges)-1)]\n",
    "plt.bar(bin_centers, frequencies, width=np.diff(bin_ranges), edgecolor='black')\n",
    "plt.xlabel('Delays [s]')\n",
    "plt.ylabel('Number of trains delayed')\n",
    "plt.title('Sunday - Train - Morning (6h-9h)')\n",
    "plt.savefig('stat.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19218cb2-d825-4790-87cc-7bf33e22652b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute the sum\n",
    "rows_sums = stat_istdaten.sum(axis=1)\n",
    "row_sum = rows_sums.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf11c83a-9f92-42e3-a36e-f2f8e65d898e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute cumulative sum\n",
    "df_cum_sum = stat_istdaten.cumsum(axis=1)\n",
    "df_cum_sum.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362df64c-d579-494a-a946-790cb34e221e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the probability for each case\n",
    "istdaten_prob = df_cum_sum.divide(row_sum, axis='rows')\n",
    "istdaten_prob.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833ab56a-3cd9-4fb1-832d-f1f6043d8b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = istdaten_prob.iloc[60].tolist()\n",
    "plt.plot(np.linspace(0,200,10), prob)\n",
    "plt.xlabel('Delays [s]')\n",
    "plt.ylabel('Probability')\n",
    "plt.title('Sunday - Train - Morning (6h-9h)')\n",
    "plt.savefig('exprob.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6dde8d-03f8-4484-994e-d3d4ee99c16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add all the combinations\n",
    "all_prob_ist = istdaten_prob.join(indexx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0659a1f2-4e0e-416a-9f27-4595f378f532",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the order of the columns\n",
    "cols = list(all_prob_ist.columns)\n",
    "cols = [cols[-1]] + cols[:-1]\n",
    "prob = all_prob_ist[cols]\n",
    "prob.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93193cba-7487-4ca2-94fc-6616b6384964",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob.to_csv('prob_istdaten.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45f5be8-4434-48f4-bce0-0591bdfcb994",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
